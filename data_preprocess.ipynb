{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocess import *\n",
    "from data_visual_tools import *\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_labels(\n",
    "    root=\"/home/ec2-user/segmenter/ETTDATA/sampled_data_split\",\n",
    "    label_dir='labels/train',\n",
    "    image_dir='images/train', target_dir='view_label',\n",
    "    annotation_file='annotations/train_annotations_enl5.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n",
      "4414\n"
     ]
    }
   ],
   "source": [
    "f = open('/home/ec2-user/segmenter/MAIDA/data1000/val_annotations_enl5.json')\n",
    "data = json.load(f)\n",
    "\n",
    "print(len(data['images']))\n",
    "print(len(data['annotations']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 image converted\n",
      "50 image converted\n",
      "100 image converted\n",
      "150 image converted\n",
      "200 image converted\n",
      "250 image converted\n",
      "300 image converted\n",
      "350 image converted\n",
      "400 image converted\n",
      "450 image converted\n",
      "500 image converted\n",
      "550 image converted\n",
      "600 image converted\n",
      "650 image converted\n",
      "700 image converted\n",
      "750 image converted\n"
     ]
    }
   ],
   "source": [
    "image_paths = get_img_path(path=\"/home/ec2-user/efs/MAIDA/normal\")\n",
    "convert_dcm(image_paths, output_path = '/home/ec2-user/segmenter/MAIDA/data1000/new_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 image converted\n",
      "50 image converted\n",
      "100 image converted\n",
      "150 image converted\n",
      "200 image converted\n",
      "250 image converted\n",
      "300 image converted\n",
      "350 image converted\n",
      "400 image converted\n",
      "450 image converted\n",
      "500 image converted\n",
      "550 image converted\n"
     ]
    }
   ],
   "source": [
    "image_paths = get_img_path(path=\"/home/ec2-user/efs/MAIDA/abnormal\")\n",
    "convert_dcm(image_paths, output_path = '/home/ec2-user/segmenter/MAIDA/data1000/new_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsize_images(\n",
    "    root=\"/home/ec2-user/segmenter/ETTDATA/Test\",\n",
    "    image_dir='RANZCR', target_dir='downsized/RANZCR', output_file='annotations_downsized.json',\n",
    "    resized_dim=1280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_reviewed_anno(ori_ann_file='/home/ec2-user/efs/MAIDA/MIMIC-1105-annotations.json',\n",
    "                  target_dir='MAIDA/data1000/annotations1105_tmp.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem ID:  [4380406, 4146693, 4380560, 4146445, 4379767, 4380433, 2946144, 4379950, 4380559, 4379731, 4380006, 4146328, 4380029, 4380713, 4146035, 4380064, 4380206]\n"
     ]
    }
   ],
   "source": [
    "generate_gt_label(\n",
    "    root=\"/home/ec2-user/segmenter/MAIDA\",\n",
    "    annotation_file='data/ett/annotations/train_annotations_enl5.json',\n",
    "    image_dir='data1000/downsized/split/images/train', out_dir='data1000/downsized/split/labels/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = pd.read_csv('/home/ec2-user/efs/MAIDA/MIMIC-train.csv')\n",
    "val_info = pd.read_csv('/home/ec2-user/efs/MAIDA/MIMIC-val.csv')\n",
    "test_info = pd.read_csv('/home/ec2-user/efs/MAIDA/MIMIC-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(root='/home/ec2-user/segmenter/MAIDA/data1000/downsized',\n",
    "                         image_dir='images', label_dir='labels', target_dir='downsized/split'):\n",
    "    src = os.path.join(root, image_dir)\n",
    "    \n",
    "    for file in os.listdir(src):\n",
    "        name = file[:-4]\n",
    "        if name in list(train_info['imageID']):\n",
    "            shutil.copy(os.path.join(src, file), os.path.join(root, target_dir, image_dir, \"train\"))\n",
    "        elif name in list(val_info['imageID']):\n",
    "            shutil.copy(os.path.join(src, file), os.path.join(root, target_dir, image_dir, \"val\"))\n",
    "        elif name in list(test_info['imageID']):\n",
    "            shutil.copy(os.path.join(src, file), os.path.join(root, target_dir, image_dir, \"test\"))\n",
    "        else:\n",
    "            print(name)\n",
    "    src = os.path.join(root, label_dir)\n",
    "    for file in os.listdir(src):\n",
    "        name = file[:-4]\n",
    "        if name in list(train_info['imageID']):\n",
    "            shutil.copy(os.path.join(src, file), os.path.join(root, target_dir, label_dir, \"train\"))\n",
    "        elif name in list(val_info['imageID']):\n",
    "            shutil.copy(os.path.join(src, file), os.path.join(root, target_dir, label_dir, \"val\"))\n",
    "        elif name in list(test_info['imageID']):\n",
    "            shutil.copy(os.path.join(src, file), os.path.join(root, target_dir, label_dir, \"test\"))\n",
    "        else:\n",
    "            print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_anno(anno_file='/home/ec2-user/segmenter/MAIDA/data1000/annotations_downsized1105.json',\n",
    "                  out_file='/home/ec2-user/segmenter/MAIDA/data1000/annotations1105.json',\n",
    "                  split_info='/home/ec2-user/segmenter/ETT_Evaluation/data_split/train_mimic_only.csv',\n",
    "                  mimic=False, ranzcr=False, split='test'):\n",
    "    # column = 'imageID'\n",
    "    column = 'FileName'\n",
    "    f = open(anno_file)\n",
    "    data = json.load(f)\n",
    "    test_images = []\n",
    "    info = pd.read_csv(split_info)\n",
    "\n",
    "    if mimic:\n",
    "        test_info = info[(info['Split']==split) & (info['Source']=='MIMIC')]\n",
    "    elif ranzcr:\n",
    "        test_info = info[(info['Split']==split) & (info['Source']=='RANZCR')]\n",
    "    else:\n",
    "        raise ValueError(\"No dataset specified.\")\n",
    "    for image in data['images']:\n",
    "        image['file_name'] = image['file_name'].replace('.dcm', '.jpg')\n",
    "        if image['file_name'][:-4] in list(test_info[column]):\n",
    "            test_images.append(image)\n",
    "\n",
    "    test_coco = {\n",
    "        'info': data['info'],\n",
    "        'categories': data['categories'],\n",
    "        'images': test_images,\n",
    "        'annotations': data['annotations']\n",
    "    }\n",
    "\n",
    "    with open(out_file, 'w') as f:\n",
    "        json.dump(test_coco, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def move_ranzcr_images(src_dir='/home/ec2-user/efs/RANZCR/data',\n",
    "                csv_file='/home/ec2-user/segmenter/ETT_Evaluation/data_split/all_data_split.csv',\n",
    "                output_dir='/home/ec2-user/segmenter/ETTDATA/Test/RANZCR', split='test', source='RANZCR'):\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Loop through the csv file\n",
    "    with open(csv_file, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            # Check if the image is in one of the subdirectories\n",
    "            for subdir_name in os.listdir(src_dir):\n",
    "                subdir_path = os.path.join(src_dir, subdir_name)\n",
    "                # print(subdir_path)\n",
    "                if not os.path.isdir(subdir_path):\n",
    "                    continue\n",
    "                img_path = os.path.join(subdir_path, row['FileName'])\n",
    "                img_path += '.jpg'\n",
    "                if os.path.isfile(img_path):\n",
    "                    # If the image is in the csv file and meets the criteria, copy it to the new directory\n",
    "                    if row['Source'] == source and row['Split'] == split:\n",
    "                        shutil.copy(img_path, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_mimic_images(src_dir='/home/ec2-user/segmenter/MAIDA/all_images',\n",
    "                csv_file='/home/ec2-user/segmenter/ETT_Evaluation/data_split/all_data_split.csv',\n",
    "                output_dir='/home/ec2-user/segmenter/ETTDATA/Test/MIMIC', split='test', source='MIMIC'):\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    info = pd.read_csv(csv_file)\n",
    "\n",
    "    target_imgs = list(info[(info['Source']==source) & (info['Split']==split)]['FileName'])\n",
    "\n",
    "    for img_path in os.listdir(src_dir):\n",
    "        if img_path.replace('.png', '') in target_imgs:\n",
    "            image = Image.open(os.path.join(src_dir, img_path))\n",
    "            img_path = img_path.replace('.png', '.jpg')\n",
    "            image.save(os.path.join(output_dir, img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move_ranzcr_images(src_dir='/home/ec2-user/efs/RANZCR/data',\n",
    "#             csv_file='/home/ec2-user/segmenter/ETT_Evaluation/data_split/sampled_data_split.csv',\n",
    "#             output_dir='/home/ec2-user/segmenter/ETTDATA/Test/RANZCR', split='test', source='RANZCR')\n",
    "\n",
    "# move_ranzcr_images(src_dir='/home/ec2-user/efs/RANZCR/data',\n",
    "#             csv_file='/home/ec2-user/segmenter/ETT_Evaluation/data_split/sampled_data_split.csv',\n",
    "#             output_dir='/home/ec2-user/segmenter/ETTDATA/sampled_data_split/train', split='train', source='RANZCR')\n",
    "\n",
    "# move_ranzcr_images(src_dir='/home/ec2-user/efs/RANZCR/data',\n",
    "#             csv_file='/home/ec2-user/segmenter/ETT_Evaluation/data_split/sampled_data_split.csv',\n",
    "#             output_dir='/home/ec2-user/segmenter/ETTDATA/sampled_data_split/val', split='val', source='RANZCR')\n",
    "\n",
    "# move_mimic_images(src_dir='/home/ec2-user/segmenter/MAIDA/all_images',\n",
    "#                 csv_file='/home/ec2-user/segmenter/ETT_Evaluation/data_split/all_data_split.csv',\n",
    "#                 output_dir='/home/ec2-user/segmenter/ETTDATA/Test/MIMIC', split='test', source='MIMIC')\n",
    "\n",
    "move_mimic_images(src_dir='/home/ec2-user/segmenter/MAIDA/all_images',\n",
    "                csv_file='/home/ec2-user/segmenter/ETT_Evaluation/data_split/train_mimic_only.csv',\n",
    "                output_dir='/home/ec2-user/segmenter/ETTDATA/mimic_only/train', split='train', source='MIMIC')\n",
    "\n",
    "move_mimic_images(src_dir='/home/ec2-user/segmenter/MAIDA/all_images',\n",
    "                csv_file='/home/ec2-user/segmenter/ETT_Evaluation/data_split/train_mimic_only.csv',\n",
    "                output_dir='/home/ec2-user/segmenter/ETTDATA/mimic_only/val', split='val', source='MIMIC')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsize_anno(ori_ann_file='/home/ec2-user/efs/RANZCR/RANZCR-ETT-annotations.json',\n",
    "#     output_file='/home/ec2-user/segmenter/ETTDATA/downsized_anno/ranzcr-downsized.json',\n",
    "#     resized_dim=1280)\n",
    "# make_bbox_nonzero(root='/home/ec2-user/segmenter/ETTDATA/downsized_anno',\n",
    "#                   anno_dir='ranzcr-downsized.json')\n",
    "# enlarge_bbox(root=\"/home/ec2-user/segmenter/ETTDATA/downsized_anno\",\n",
    "#              annotation_file='ranzcr-downsized.json',\n",
    "#              out_file='ranzcr-enlarged5.json', factor=5)\n",
    "# create_area(file='/home/ec2-user/segmenter/ETTDATA/downsized_anno/ranzcr-enlarged5.json')\n",
    "# get_test_anno(anno_file='/home/ec2-user/segmenter/ETTDATA/downsized_anno/ranzcr-enlarged5.json',\n",
    "#               out_file='/home/ec2-user/segmenter/ETTDATA/Test/downsized/RANZCR/annotations/test_annotations_enl5.json',\n",
    "#               split_info='/home/ec2-user/segmenter/ETT_Evaluation/data_split/train_mimic_only.csv',\n",
    "#               mimic=False, ranzcr=True)\n",
    "# downsize_images(root=\"/home/ec2-user/segmenter/ETTDATA/Test\",\n",
    "#     image_dir='RANZCR', target_dir='downsized/RANZCR/images',\n",
    "#     resized_dim=1280)\n",
    "\n",
    "\n",
    "\n",
    "# downsize_anno(ori_ann_file='/home/ec2-user/segmenter/ETT_Evaluation/MIMIC-ETT-annotations-cleaned.json',\n",
    "#     output_file='/home/ec2-user/segmenter/ETTDATA/downsized_anno/mimic-downsized.json',\n",
    "#     resized_dim=1280)\n",
    "# make_bbox_nonzero(root='/home/ec2-user/segmenter/ETTDATA/downsized_anno',\n",
    "#                   anno_dir='mimic-downsized.json')\n",
    "# enlarge_bbox(root=\"/home/ec2-user/segmenter/ETTDATA/downsized_anno\",\n",
    "#              annotation_file='mimic-downsized.json',\n",
    "#              out_file='mimic-enlarged5.json', factor=5)\n",
    "# create_area(file='/home/ec2-user/segmenter/ETTDATA/downsized_anno/mimic-enlarged5.json')\n",
    "get_test_anno(anno_file='/home/ec2-user/segmenter/ETTDATA/downsized_anno/mimic-enlarged5.json',\n",
    "              out_file='/home/ec2-user/segmenter/ETTDATA/Test/downsized/MIMIC/annotations/test_annotations_enl5.json',\n",
    "              split_info='/home/ec2-user/segmenter/ETT_Evaluation/data_split/train_mimic_only.csv',\n",
    "              mimic=True, ranzcr=False)\n",
    "# downsize_images(root=\"/home/ec2-user/segmenter/ETTDATA/Test\",\n",
    "#     image_dir='MIMIC', target_dir='downsized/MIMIC/images',\n",
    "#     resized_dim=1280)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get_test_anno(anno_file='/home/ec2-user/segmenter/ETTDATA/downsized_anno/mimic-enlarged5.json',\n",
    "#               out_file='/home/ec2-user/segmenter/ETTDATA/train_mimic_only/annotations/train_mimic_annotations_enl5.json',\n",
    "#               split_info='/home/ec2-user/segmenter/ETT_Evaluation/data_split/train_mimic_only.csv',\n",
    "#               mimic=True, ranzcr=False, split='train')\n",
    "# get_test_anno(anno_file='/home/ec2-user/segmenter/ETTDATA/downsized_anno/mimic-enlarged5.json',\n",
    "#               out_file='/home/ec2-user/segmenter/ETTDATA/train_mimic_only/annotations/val_mimic_annotations_enl5.json',\n",
    "#               split_info='/home/ec2-user/segmenter/ETT_Evaluation/data_split/train_mimic_only.csv',\n",
    "#               mimic=True, ranzcr=False, split='val')\n",
    "\n",
    "# get_test_anno(anno_file='/home/ec2-user/segmenter/ETTDATA/downsized_anno/ranzcr-enlarged5.json',\n",
    "#               out_file='/home/ec2-user/segmenter/ETTDATA/sampled_data_split/annotations/train_ranzcr_annotations_enl5.json',\n",
    "#               split_info='/home/ec2-user/segmenter/ETT_Evaluation/data_split/sampled_data_split.csv',\n",
    "#               mimic=False, ranzcr=True, split='train')\n",
    "# get_test_anno(anno_file='/home/ec2-user/segmenter/ETTDATA/downsized_anno/ranzcr-enlarged5.json',\n",
    "#               out_file='/home/ec2-user/segmenter/ETTDATA/sampled_data_split/annotations/val_ranzcr_annotations_enl5.json',\n",
    "#               split_info='/home/ec2-user/segmenter/ETT_Evaluation/data_split/sampled_data_split.csv',\n",
    "#               mimic=False, ranzcr=True, split='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_anno(anno1, anno2, output_anno):\n",
    "    with open(anno1) as f1:\n",
    "        data1 = json.load(f1)\n",
    "    with open(anno2) as f2:\n",
    "        data2 = json.load(f2)\n",
    "\n",
    "    data = {}\n",
    "    data['categories'] = data1['categories'] # same for mimic and ranzcr\n",
    "    data['images'] = data1['images']\n",
    "    data['images'].extend(data2['images'])\n",
    "\n",
    "    data['annotations'] = data1['annotations']\n",
    "    data['annotations'].extend(data2['annotations'])\n",
    "\n",
    "    with open(output_anno, 'w') as f:\n",
    "        json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine_anno('/home/ec2-user/segmenter/ETTDATA/sampled_data_split/annotations/val_mimic_annotations_enl5.json',\n",
    "#              '/home/ec2-user/segmenter/ETTDATA/sampled_data_split/annotations/val_ranzcr_annotations_enl5.json',\n",
    "#              '/home/ec2-user/segmenter/ETTDATA/sampled_data_split/annotations/val_annotations_enl5.json')\n",
    "# combine_anno('/home/ec2-user/segmenter/ETTDATA/sampled_data_split/annotations/train_mimic_annotations_enl5.json',\n",
    "#              '/home/ec2-user/segmenter/ETTDATA/sampled_data_split/annotations/train_ranzcr_annotations_enl5.json',\n",
    "#              '/home/ec2-user/segmenter/ETTDATA/sampled_data_split/annotations/train_annotations_enl5.json')\n",
    "\n",
    "downsize_images(root=\"/home/ec2-user/segmenter/ETTDATA/sampled_data_split\",\n",
    "    image_dir='val', target_dir='val',\n",
    "    resized_dim=1280)\n",
    "\n",
    "downsize_images(root=\"/home/ec2-user/segmenter/ETTDATA/sampled_data_split\",\n",
    "    image_dir='train', target_dir='train',\n",
    "    resized_dim=1280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem ID:  [4146445, 2946144, 4380406]\n",
      "Problem ID:  [4146693, 4146035, 4146193, 4380560, 4379767, 4380433, 4380559, 4380006, 4380029, 4380713, 4380064, 4380206]\n"
     ]
    }
   ],
   "source": [
    "from data_preprocess import *\n",
    "generate_gt_label(\n",
    "    root=\"/home/ec2-user/segmenter/ETTDATA/train_mimic_only/\",\n",
    "    annotation_file='annotations/val_annotations_enl5.json',\n",
    "    image_dir='images/val', out_dir='labels/val')\n",
    "generate_gt_label(\n",
    "    root=\"/home/ec2-user/segmenter/ETTDATA/train_mimic_only/\",\n",
    "    annotation_file='annotations/train_annotations_enl5.json',\n",
    "    image_dir='images/train', out_dir='labels/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the dataset:  [126.55846604 126.55846604 126.55846604]\n",
      "Std of the dataset:  [55.47551373 55.47551373 55.47551373]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([126.55846604, 126.55846604, 126.55846604]),\n",
       " array([55.47551373, 55.47551373, 55.47551373]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stats(root=\"/home/ec2-user/segmenter/MAIDA/data1000\", image_dir='downsized/split/images/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split_anno(\n",
    "                         anno_dir='/home/ec2-user/segmenter/MAIDA/data1000/annotations_downsized1105.json',\n",
    "                         out_dir='/home/ec2-user/segmenter/MAIDA/data1000'):\n",
    "    f = open(anno_dir)\n",
    "    data = json.load(f)\n",
    "    train_images = []\n",
    "    val_images = []\n",
    "    test_images = []\n",
    "    for image in data['images']:\n",
    "        image['file_name'] = image['file_name'].replace('.dcm', '.png')\n",
    "        if image['file_name'][:-4] in list(train_info['imageID']):\n",
    "            train_images.append(image)\n",
    "        elif image['file_name'][:-4] in list(val_info['imageID']):\n",
    "            val_images.append(image)\n",
    "        elif image['file_name'][:-4] in list(test_info['imageID']):\n",
    "            test_images.append(image)\n",
    "        else: \n",
    "            print(image)\n",
    "    train_coco = {\n",
    "        'info': data['info'],\n",
    "        'categories': data['categories'],\n",
    "        'images': train_images,\n",
    "        'annotations': data['annotations']\n",
    "    }\n",
    "\n",
    "    val_coco = {\n",
    "        'info': data['info'],\n",
    "        'categories': data['categories'],\n",
    "        'images': val_images,\n",
    "        'annotations': data['annotations']\n",
    "    }\n",
    "\n",
    "    test_coco = {\n",
    "        'info': data['info'],\n",
    "        'categories': data['categories'],\n",
    "        'images': test_images,\n",
    "        'annotations': data['annotations']\n",
    "    }\n",
    "\n",
    "    with open(os.path.join(out_dir, 'train_annotations.json'), 'w') as f:\n",
    "        json.dump(train_coco, f)\n",
    "\n",
    "    with open(os.path.join(out_dir, 'val_annotations.json'), 'w') as f:\n",
    "        json.dump(val_coco, f)\n",
    "\n",
    "    with open(os.path.join(out_dir, 'test_annotations.json'), 'w') as f:\n",
    "        json.dump(test_coco, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_test_split_anno(anno_dir='/home/ec2-user/segmenter/ETT_Evaluation/MIMIC-ETT-annotations-cleaned.json',\n",
    "            out_dir='/home/ec2-user/segmenter/ETTDATA/Test/annotations/RANZCR'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero boxes: 0\n"
     ]
    }
   ],
   "source": [
    "make_bbox_nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('/home/ec2-user/segmenter/MAIDA/data1000/annotations1105.json')\n",
    "# data = json.load(f)\n",
    "# for ann in data['images']:\n",
    "#     ann['file_name'] = ann['file_name'].replace('.dcm', '.png')\n",
    "# with open('/home/ec2-user/segmenter/MAIDA/data1000/annotations1105.json', 'w') as f:\n",
    "#     json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsize_anno(ori_ann_file='MIMIC-2k-annotations.json',\n",
    "    root=\"/home/ec2-user/segmenter/MAIDA\",\n",
    "    output_file='annotations-downsized-2k.json',\n",
    "    resized_dim=1280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero boxes: 0\n"
     ]
    }
   ],
   "source": [
    "make_bbox_nonzero(root='/home/ec2-user/segmenter/MAIDA',\n",
    "                         anno_dir='annotations-downsized-2k.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "enlarge_bbox(root=\"/home/ec2-user/segmenter/MAIDA\",\n",
    "             annotation_file='annotations-downsized-2k.json', factor=5)\n",
    "# generate_gt_label(\n",
    "#     root=\"/home/ec2-user/segmenter/MAIDA/data1000\",\n",
    "#     annotation_file='annotations_enlarged_5.json',\n",
    "#     image_dir='downsized/images', out_dir='downsized/labels')\n",
    "# train_val_test_split_anno(root='/home/ec2-user/segmenter/MAIDA/data1000',\n",
    "#                          anno_dir='annotations_enlarged_5.json')\n",
    "# train_val_test_split(root='/home/ec2-user/segmenter/MAIDA/data1000/downsized',\n",
    "#                          image_dir='images', label_dir='labels', target_dir='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "make4classes(file='/home/ec2-user/segmenter/MAIDA/data1000/val_annotations.json',\n",
    "        outfile='/home/ec2-user/segmenter/MAIDA/data1000/val_annotations_4cls.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='/home/ec2-user/segmenter/MAIDA/data1000/annotations1105_tmp.json'\n",
    "m = {}\n",
    "rep = []\n",
    "with open(file) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for ann in data['annotations']:\n",
    "    key = (ann['image_id'], ann['category_id'])\n",
    "    if key not in m.keys():\n",
    "        m[key] = 0\n",
    "    m[key] += 1\n",
    "    # elif ann['category_id'] == 3046 or ann['category_id'] == 3047:\n",
    "    #     prev = m[key]\n",
    "    #     # if ann['bbox'] == prev['bbox'] and ann['assignee'] == prev['assignee']:\n",
    "    #     #     data['annotations'].remove(ann)\n",
    "    #     # else:\n",
    "    #     rep.append(ann)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_area(file='/home/ec2-user/segmenter/MAIDA/annotations_enlarged_5.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_2k = open('/home/ec2-user/segmenter/MAIDA/annotations_enlarged_5.json')\n",
    "f_train = open('/home/ec2-user/segmenter/MAIDA/data/ett/annotations/train_annotations_enl5.json')\n",
    "f_val = open('/home/ec2-user/segmenter/MAIDA/data/ett/annotations/val_annotations_enl5.json')\n",
    "f_test = open('/home/ec2-user/segmenter/MAIDA/data/ett/annotations/test_annotations_enl5.json')\n",
    "\n",
    "data_2k = json.load(f_2k)\n",
    "data_train = json.load(f_train)\n",
    "data_val = json.load(f_val)\n",
    "data_test = json.load(f_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ids = [i['id'] for i in data_val['images']]\n",
    "test_ids = [i['id'] for i in data_test['images']]\n",
    "train_ids = [i['id'] for i in data_train['images']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rep_ids = [i['image_id'] for i in rep]\n",
    "# print(len(rep_ids))\n",
    "cnt = 0\n",
    "tmp = 0\n",
    "for ann in data_2k['images']:\n",
    "    if ann['id'] not in val_ids and ann['id'] not in test_ids and ann['id'] not in train_ids:\n",
    "        data_train['images'].append(ann)\n",
    "        tmp += 1\n",
    "    else:\n",
    "        cnt += 1\n",
    "data_train['annotations'] = data_2k['annotations']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1105, 1336)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt, tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2109"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train['images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ec2-user/segmenter/MAIDA/data/ett/annotations/train_annotations_enl5.json', 'w') as outfile:\n",
    "    json.dump(data_train, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('/home/ec2-user/segmenter/MAIDA/data/ett/annotations/train_annotations_enl5.json')\n",
    "data_train = json.load(f)\n",
    "\n",
    "for ann in data_train['images']:\n",
    "    ann['file_name'] = ann['file_name'].replace('.dcm', '.png')\n",
    "\n",
    "with open('/home/ec2-user/segmenter/MAIDA/data/ett/annotations/train_annotations_enl5.json', 'w') as outfile:\n",
    "    json.dump(data_train, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
